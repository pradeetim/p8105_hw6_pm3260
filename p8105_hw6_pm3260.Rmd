---
title: "p8105_hw6_pm3260"
author: "Pradeeti Mainali"
date: "2024-11-21"
output: github_document
---

```{r setup, message=FALSE}
library(tidyverse)
library(rnoaa)
library(purrr)
library(modelr)
```

# Problem 1 (no points)

Unable to load the data set. Issue with the dates avaiable for the ID needed for this problem.

# Problem 2

### Data cleaning/setup:

```{r washpost, warning=FALSE}
homicide = 
  read.csv("data/homicide-data.csv")|>
  janitor::clean_names() |>
  mutate(
    state = str_to_upper(state),
    city_state = str_c(city, ", ", state),
    solved = case_when(
      disposition == "Closed by arrest" ~ 1, 
      disposition %in% c("Closed without arrest", "Open/No arrest") ~ 0),
      victim_age = as.numeric(victim_age)
    ) |>
  filter(
    victim_race %in% c("White", "Black"),
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")
    )

```

### Adjusted OR and 95% CI for Baltimore, MD:

```{r balt}
homicide_balt =
  homicide |>
  filter(city_state == "Baltimore, MD") |>
  glm(solved ~ victim_age + victim_race + victim_sex, data = _, 
      family = binomial()) |>
  broom::tidy() |>
  mutate(OR = exp(estimate),
         conf.low = exp(estimate - 1.96 * std.error),
         conf.high = exp(estimate + 1.96 * std.error)
         ) |>
  filter(term == "victim_sexMale") |>
  select(OR, conf.low, conf.high)
```

#### Interpretation: 

Adjusted OR: 0.4255117

Adjusted 95% CI: (0.324559, 0.5578655)

Adjusting for age and race, the estimated odds of having a solved case for those identifying as female is 0.43 times the odds of having a solved case for those identifying as male. We are 95% confident that the true OR lies between 0.325 and 0.558.

### Adjusted OR and 95% CI for all cities in dataset.

```{r all_cities}
homicide_cities =
  homicide |>
  group_by(city_state) |>
  nest() |>
  mutate(
    glm_results = map(data, ~glm(solved ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    tidy_results = map(glm_results, ~broom::tidy(.x))) |>
  mutate(
    or_city = map(tidy_results, ~ .x |>
                  filter(term == "victim_sexMale") |>
                  mutate(
                    OR = exp(estimate),
                    conf.low = exp(estimate - 1.96 * std.error),
                    conf.high = exp(estimate + 1.96 * std.error))|>
                  select(OR, conf.low, conf.high))) |>
  unnest(or_city) |>
  select(city_state, OR, conf.low, conf.high)

```

### Plot of Adjusted OR and 95% CI for Solved Homicides by Sex by City

```{r plot_cities, fig.height=8}
ggplot(homicide_cities, aes(x = reorder(city_state, OR), y = OR)) +
  geom_point(size = 2, color = "black") +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2, color = "hotpink") +
  coord_flip() +
  labs(
    title = "Adjusted Odds Ratios (OR) for Solved Homicides (Male vs Female Victims) by City",
    x = "City, State",
    y = "Adjusted Odds Ratio (OR)",
    caption = "ORs and CIs are adjusted for victim age and race"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 8),  
    plot.title = element_text(hjust = 0.5), 
    plot.caption = element_text(hjust = 0.5))
```

#### Description:

Only 4 cities have ORs over 1, meaning there is a higher odds for females in having a solved case than males. However, even these cities have their CI encompass the null value of 1 and below, meaning that there is a chance the estimated adjusted OR is the same as the true adjusted odds. 

New York has the smallest OR, meaning victims who identify as women have the least odds of having a solved case here than the other cities in this data set. 

# Problem 3

```{r bwt}
birthweight_df =
  read.csv("data/birthweight.csv") |>
  janitor::clean_names() |>
  mutate(
    babysex = factor(babysex, levels = c(1, 2), 
                     labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), 
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), 
                     labels = c("Absent", "Present")))
```

#### Regression Model:

```{r regression}
fit_1 =
  lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight_df) 


fit_1 |>
  broom::tidy() |>
  mutate(
    p.value = format.pval(p.value, scientific = FALSE)
  ) |>
  knitr::kable()

```

Model based on hypothesized structure for the factors. All the independent factors are hypothesized to be associated with bwt. Additionally, their p-value in a full model were lower than 0.05.

The process involved starting with a full model and removing the variable with the highest p-value above 0.05 and then rerunning the regression model until all the variables had p-values under 0.05.

#### Residual Plot: 

```{r residuals, message=FALSE}
birthweight_df =
  birthweight_df |>
  modelr::add_residuals(fit_1) |>
  modelr::add_predictions(fit_1)

ggplot(birthweight_df, aes(x = pred, y = resid)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(title = "Residuals vs Fitted Values",
       x = "Fitted Values", 
       y = "Residuals") +
  theme_minimal()
```

The residuals plot shows the data points spread around zero, which is idicative of goodness of fit for this model. However, there are a few outliers. 

### Comparison with other models:

```{r other_lm}
fit_2 = 
  lm(bwt ~ blength + gaweeks, data = birthweight_df)

fit_3 = 
  lm(bwt ~ bhead * blength * babysex, data = birthweight_df)
```

#### Cross validation:

```{r crossv, warning=FALSE}
cv_df = 
  crossv_mc(birthweight_df, 100)

cv_res_df = 
  cv_df |>
  mutate(
    fit_1 = map(train, \(x) lm(bwt ~ babysex + bhead + blength + delwt + 
                               gaweeks + mheight + mrace + parity + 
                               ppwt + smoken, data = x)),
    fit_2 = map(train, \(x) lm(bwt ~ blength + gaweeks, data = x)),
    fit_3 = map(train, \(x) lm(bwt ~ bhead * blength * babysex, data = x))
  ) |>
  mutate(
    rmse_model_1 = map2_dbl(fit_1, test, rmse),
    rmse_model_2 = map2_dbl(fit_2, test, rmse),
    rmse_model_3 = map2_dbl(fit_3, test, rmse)
  )

cv_res_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(
    model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

With the cross validation prediction error, we compared the three linear models. We can see that the first model has a much lower RMSE, meaning that the model's predictions are closer to the actual observed values, on average. 

It reflects better accuracy and suggests that the model is performing well at capturing the relationship between the predictors and the response variable.

However, this could be because the model that I proposed has a lot of variables. The second most accurate model is model 3, the one with the interaction terms. 
